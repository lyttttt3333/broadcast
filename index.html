<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Broadcasting Support Relations Recursively from Local Dynamics for Object Retrieval in Clutters.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Broadcasting Support Relations Recursively from Local Dynamics for Object Retrieval in Clutters</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>




<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Broadcasting Support Relations Recursively from Local Dynamics for Object Retrieval in Clutters</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://lyttttt3333.github.io/YitongLi.github.io/">Yitong Li</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://warshallrho.github.io/">Ruihai Wu</a><sup>1,4</sup>,</span>         
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=wNDTItAAAAAJ">Haoran Lu</a><sup>1,4</sup>,
            </span>
            <span class="author-block">
              <a href="https://tritiumr.github.io/">Chuanruo Ning</a><sup>1,4</sup>,
            </span>
            <span class="author-block">
              <a href="https://sxy7147.github.io/">Yan Shen</a><sup>1,4</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.robots.ox.ac.uk/~guanqi/">Guanqi Zhan</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://zsdonghao.github.io/">Hao Dong</a><sup>1,4</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>CFCS, School of CS, PKU</span>
            <span class="author-block"><sup>2</sup>Weiyang College, THU</span>
            <span class="author-block"><sup>3</sup>University of Oxford</span>
            <span class="author-block"><sup>4</sup>National Key Laboratory for Multimedia Information Processing, School of CS, PKU</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2406.02283"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=vUCDVfrvOrg"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/lyttttt3333/Broadcast_Support_Relation"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body is-flex is-flex-direction-column is-align-items-center">
      <img src="./static/images/1.jpg"
        class="image"
        alt="Interpolate start reference image."/>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In our daily life, cluttered objects are everywhere, from scattered stationery and books cluttering the table to bowls and plates filling the kitchen sink. Retrieving a target object from clutters is an essential while challenging skill for robots, for the difficulty of safely manipulating an object without disturbing others, which requires the robot to plan a manipulation sequence and first move away a few other objects supported by the target object step by step. However, due to the diversity of object configurations (e.g., categories, geometries, locations and poses) and their combinations in clutters, it is difficult for a robot to accurately infer the support relations between objects faraway with various objects in between. In this paper, we study retrieving objects in complicated clutters via a novel method of recursively broadcasting the accurate local dynamics to build a support relation graph of the whole scene, which largely reduces the complexity of the support relation inference and improves the accuracy. Experiments in both simulation and the real world demonstrate the efficiency and effectiveness of our method.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body is-flex is-flex-direction-column is-align-items-center">
      <img src="./static/images/2.jpg"
        class="image"
        alt="Interpolate start reference image."/>
      <p class="has-text-centered mt-4">
        Directly modelling the support relations between any two objects in clutters is difficult and inaccurate, as object relations between two distant objects could be highly complicated and hard to predict.
        To tackle this problem, we build the whole support relation graph of the cluttered objects by broadcasting the more accurate local dynamics between adjacent objects recursively
        , with the assistance of Retrieval Direction Predictor and Local Dynamics Predictor.
      </p>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body is-flex is-flex-direction-column is-align-items-center">
      <img src="./static/images/3.jpg"
        class="image"
        alt="Interpolate start reference image."/>
      <p class="has-text-centered mt-4">
        (Left) When the occlusions are removed, more detailed information will be revealed. To eliminate the impact of occlusions, we propose the Graph
        Adjustment process.
        (Right) We propose Affordance as grasping guidance. The estimation of affordance scores for various points necessitates a comprehensive consideration of both the object's geometry and its surrounding environment.
      </p>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/video0.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        This video demonstrate the process of Recursive Broadcast, which start from the final target and search along the potential supported chain until objects on the top.
        In this way, we overcome the difficulty of long horizon dependency in physical detection and could predict accurate relationship.
      </h2>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video2.mp4"
                    type="video/mp4">
          </video>

        </div>
      </div>
      <h2 class="subtitle has-text-centered">
        Some examples of our real world experiments
      </h2>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/intro.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        A detailed introduction video of our project
      </h2>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{li2024broadcastingsupportrelationsrecursively,
        title={Broadcasting Support Relations Recursively from Local Dynamics for Object Retrieval in Clutters}, 
        author={Yitong Li and Ruihai Wu and Haoran Lu and Chuanruo Ning and Yan Shen and Guanqi Zhan and Hao Dong},
        year={2024},
        eprint={2406.02283},
        archivePrefix={arXiv},
        primaryClass={cs.RO},
        url={https://arxiv.org/abs/2406.02283}, 
  }
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
